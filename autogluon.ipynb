{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.read_csv('train_feature.csv',header=None).values\n",
    "train_label = pd.read_csv('train_label.csv', header=None).values\n",
    "test_feature = pd.read_csv('test_feature.csv', header=None).values\n",
    "test_label = pd.read_csv('test_label.csv', header=None).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(np.concatenate((train_feature, train_label), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220907_144813\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220907_144813\\\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    61582\n",
      "Train Data Columns: 64\n",
      "Label Column: 64\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0.0, 1.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24268.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 31.53 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 64 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 64 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t64 features in original data used to generate 64 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 31.53 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.59s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.040596278133220746, Train Rows: 59082, Val Rows: 2500\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.744\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t3.56s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.7548\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t2.86s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\tTraining LightGBMXT with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.7536\t = Validation score   (accuracy)\n",
      "\t6.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\tTraining LightGBM with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.7592\t = Validation score   (accuracy)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7728\t = Validation score   (accuracy)\n",
      "\t12.43s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.77\t = Validation score   (accuracy)\n",
      "\t17.17s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "d:\\conda\\envs\\autogluon\\lib\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "\tTraining CatBoost with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\t0.7528\t = Validation score   (accuracy)\n",
      "\t3.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7704\t = Validation score   (accuracy)\n",
      "\t2.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7684\t = Validation score   (accuracy)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7904\t = Validation score   (accuracy)\n",
      "\t48.5s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.7652\t = Validation score   (accuracy)\n",
      "\t3.84s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7968\t = Validation score   (accuracy)\n",
      "\t80.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tTraining LightGBMLarge with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\t0.7736\t = Validation score   (accuracy)\n",
      "\t16.23s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7972\t = Validation score   (accuracy)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 213.74s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220907_144813\\\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=64).fit(\n",
    "    train_set,\n",
    "    ag_args_fit = {'num_gpus':1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.73\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(pd.DataFrame(test_feature)).values\n",
    "predictions = [round(value) for value in y_pred]\n",
    "acc = accuracy_score(test_label, predictions)\n",
    "print(f'test accuracy : {acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.068327</td>\n",
       "      <td>-0.947985</td>\n",
       "      <td>-0.975515</td>\n",
       "      <td>-1.077204</td>\n",
       "      <td>-1.149381</td>\n",
       "      <td>-1.051304</td>\n",
       "      <td>-1.071660</td>\n",
       "      <td>-1.067095</td>\n",
       "      <td>-1.020937</td>\n",
       "      <td>-1.015593</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.760131</td>\n",
       "      <td>-1.753883</td>\n",
       "      <td>-1.787675</td>\n",
       "      <td>-1.781121</td>\n",
       "      <td>-1.780688</td>\n",
       "      <td>-1.787004</td>\n",
       "      <td>-1.828645</td>\n",
       "      <td>-1.866022</td>\n",
       "      <td>-1.904408</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.343622</td>\n",
       "      <td>-1.289110</td>\n",
       "      <td>-1.360046</td>\n",
       "      <td>-1.218911</td>\n",
       "      <td>-1.148134</td>\n",
       "      <td>-1.244170</td>\n",
       "      <td>-1.265160</td>\n",
       "      <td>-1.302837</td>\n",
       "      <td>-1.319055</td>\n",
       "      <td>-1.133942</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.240023</td>\n",
       "      <td>-0.823620</td>\n",
       "      <td>-1.014383</td>\n",
       "      <td>-1.220561</td>\n",
       "      <td>-1.130455</td>\n",
       "      <td>-0.943635</td>\n",
       "      <td>-1.022594</td>\n",
       "      <td>-1.347723</td>\n",
       "      <td>-1.262053</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.098915</td>\n",
       "      <td>-1.067340</td>\n",
       "      <td>-1.072712</td>\n",
       "      <td>-1.068327</td>\n",
       "      <td>-1.045121</td>\n",
       "      <td>-1.135593</td>\n",
       "      <td>-1.302837</td>\n",
       "      <td>-1.369041</td>\n",
       "      <td>-1.404851</td>\n",
       "      <td>-1.384406</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.291524</td>\n",
       "      <td>-1.314247</td>\n",
       "      <td>-1.302837</td>\n",
       "      <td>-1.220705</td>\n",
       "      <td>-1.157750</td>\n",
       "      <td>-1.139700</td>\n",
       "      <td>-1.112907</td>\n",
       "      <td>-1.089455</td>\n",
       "      <td>-1.098915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.068327</td>\n",
       "      <td>-1.057988</td>\n",
       "      <td>-1.117403</td>\n",
       "      <td>-0.908180</td>\n",
       "      <td>-0.725880</td>\n",
       "      <td>-0.852189</td>\n",
       "      <td>-0.954447</td>\n",
       "      <td>-0.884544</td>\n",
       "      <td>-0.937274</td>\n",
       "      <td>-1.086875</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.148298</td>\n",
       "      <td>-1.051331</td>\n",
       "      <td>-1.083466</td>\n",
       "      <td>-1.150795</td>\n",
       "      <td>-1.149457</td>\n",
       "      <td>-1.186974</td>\n",
       "      <td>-1.105832</td>\n",
       "      <td>-0.935538</td>\n",
       "      <td>-1.098915</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.180484</td>\n",
       "      <td>-1.089019</td>\n",
       "      <td>-1.117933</td>\n",
       "      <td>-0.852418</td>\n",
       "      <td>-0.792158</td>\n",
       "      <td>-0.979361</td>\n",
       "      <td>-0.995832</td>\n",
       "      <td>-1.098915</td>\n",
       "      <td>-1.109839</td>\n",
       "      <td>-1.015386</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.313787</td>\n",
       "      <td>-1.302837</td>\n",
       "      <td>-1.221458</td>\n",
       "      <td>-1.305225</td>\n",
       "      <td>-1.374987</td>\n",
       "      <td>-1.401440</td>\n",
       "      <td>-1.335910</td>\n",
       "      <td>-1.098254</td>\n",
       "      <td>-0.945974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61577</th>\n",
       "      <td>1.985568</td>\n",
       "      <td>1.745839</td>\n",
       "      <td>1.982378</td>\n",
       "      <td>2.223944</td>\n",
       "      <td>2.018867</td>\n",
       "      <td>1.676260</td>\n",
       "      <td>2.367703</td>\n",
       "      <td>3.448178</td>\n",
       "      <td>3.155298</td>\n",
       "      <td>2.142271</td>\n",
       "      <td>...</td>\n",
       "      <td>1.118953</td>\n",
       "      <td>1.032535</td>\n",
       "      <td>0.631479</td>\n",
       "      <td>0.155188</td>\n",
       "      <td>-0.087155</td>\n",
       "      <td>0.207239</td>\n",
       "      <td>0.839108</td>\n",
       "      <td>1.221300</td>\n",
       "      <td>0.756688</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61578</th>\n",
       "      <td>0.987618</td>\n",
       "      <td>1.101565</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.732577</td>\n",
       "      <td>0.802208</td>\n",
       "      <td>1.071639</td>\n",
       "      <td>1.349028</td>\n",
       "      <td>1.430887</td>\n",
       "      <td>1.355096</td>\n",
       "      <td>1.293534</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.025395</td>\n",
       "      <td>-1.369435</td>\n",
       "      <td>-1.278301</td>\n",
       "      <td>-1.246446</td>\n",
       "      <td>-0.365553</td>\n",
       "      <td>0.531230</td>\n",
       "      <td>0.347775</td>\n",
       "      <td>-0.008108</td>\n",
       "      <td>0.690708</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61579</th>\n",
       "      <td>0.822668</td>\n",
       "      <td>1.044932</td>\n",
       "      <td>0.911287</td>\n",
       "      <td>0.881863</td>\n",
       "      <td>1.067183</td>\n",
       "      <td>1.064835</td>\n",
       "      <td>1.179654</td>\n",
       "      <td>1.344650</td>\n",
       "      <td>1.226065</td>\n",
       "      <td>1.232224</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.221460</td>\n",
       "      <td>-1.408459</td>\n",
       "      <td>-0.411164</td>\n",
       "      <td>0.336438</td>\n",
       "      <td>0.193833</td>\n",
       "      <td>0.161643</td>\n",
       "      <td>0.242989</td>\n",
       "      <td>0.275385</td>\n",
       "      <td>0.113382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61580</th>\n",
       "      <td>0.501015</td>\n",
       "      <td>0.218483</td>\n",
       "      <td>0.595794</td>\n",
       "      <td>0.816984</td>\n",
       "      <td>0.613240</td>\n",
       "      <td>0.757480</td>\n",
       "      <td>0.880369</td>\n",
       "      <td>0.632975</td>\n",
       "      <td>0.428024</td>\n",
       "      <td>0.565383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896995</td>\n",
       "      <td>0.632975</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>0.756833</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.316419</td>\n",
       "      <td>-0.149685</td>\n",
       "      <td>-0.804837</td>\n",
       "      <td>-1.494884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61581</th>\n",
       "      <td>0.987618</td>\n",
       "      <td>0.817318</td>\n",
       "      <td>0.872861</td>\n",
       "      <td>1.021832</td>\n",
       "      <td>1.132745</td>\n",
       "      <td>1.149466</td>\n",
       "      <td>1.145241</td>\n",
       "      <td>1.193910</td>\n",
       "      <td>1.347162</td>\n",
       "      <td>1.532163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545217</td>\n",
       "      <td>0.326814</td>\n",
       "      <td>0.242377</td>\n",
       "      <td>0.280322</td>\n",
       "      <td>0.414618</td>\n",
       "      <td>0.609469</td>\n",
       "      <td>0.775086</td>\n",
       "      <td>0.790413</td>\n",
       "      <td>0.534005</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61582 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -1.068327 -0.947985 -0.975515 -1.077204 -1.149381 -1.051304 -1.071660   \n",
       "1     -1.343622 -1.289110 -1.360046 -1.218911 -1.148134 -1.244170 -1.265160   \n",
       "2     -1.098915 -1.067340 -1.072712 -1.068327 -1.045121 -1.135593 -1.302837   \n",
       "3     -1.068327 -1.057988 -1.117403 -0.908180 -0.725880 -0.852189 -0.954447   \n",
       "4     -1.180484 -1.089019 -1.117933 -0.852418 -0.792158 -0.979361 -0.995832   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "61577  1.985568  1.745839  1.982378  2.223944  2.018867  1.676260  2.367703   \n",
       "61578  0.987618  1.101565  0.916388  0.732577  0.802208  1.071639  1.349028   \n",
       "61579  0.822668  1.044932  0.911287  0.881863  1.067183  1.064835  1.179654   \n",
       "61580  0.501015  0.218483  0.595794  0.816984  0.613240  0.757480  0.880369   \n",
       "61581  0.987618  0.817318  0.872861  1.021832  1.132745  1.149466  1.145241   \n",
       "\n",
       "             7         8         9   ...        55        56        57  \\\n",
       "0     -1.067095 -1.020937 -1.015593  ... -1.760131 -1.753883 -1.787675   \n",
       "1     -1.302837 -1.319055 -1.133942  ... -1.240023 -0.823620 -1.014383   \n",
       "2     -1.369041 -1.404851 -1.384406  ... -1.291524 -1.314247 -1.302837   \n",
       "3     -0.884544 -0.937274 -1.086875  ... -1.148298 -1.051331 -1.083466   \n",
       "4     -1.098915 -1.109839 -1.015386  ... -1.313787 -1.302837 -1.221458   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "61577  3.448178  3.155298  2.142271  ...  1.118953  1.032535  0.631479   \n",
       "61578  1.430887  1.355096  1.293534  ... -1.025395 -1.369435 -1.278301   \n",
       "61579  1.344650  1.226065  1.232224  ... -1.221460 -1.408459 -0.411164   \n",
       "61580  0.632975  0.428024  0.565383  ...  0.896995  0.632975  0.740047   \n",
       "61581  1.193910  1.347162  1.532163  ...  0.545217  0.326814  0.242377   \n",
       "\n",
       "             58        59        60        61        62        63   64  \n",
       "0     -1.781121 -1.780688 -1.787004 -1.828645 -1.866022 -1.904408  0.0  \n",
       "1     -1.220561 -1.130455 -0.943635 -1.022594 -1.347723 -1.262053  0.0  \n",
       "2     -1.220705 -1.157750 -1.139700 -1.112907 -1.089455 -1.098915  0.0  \n",
       "3     -1.150795 -1.149457 -1.186974 -1.105832 -0.935538 -1.098915  0.0  \n",
       "4     -1.305225 -1.374987 -1.401440 -1.335910 -1.098254 -0.945974  0.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "61577  0.155188 -0.087155  0.207239  0.839108  1.221300  0.756688  1.0  \n",
       "61578 -1.246446 -0.365553  0.531230  0.347775 -0.008108  0.690708  1.0  \n",
       "61579  0.336438  0.193833  0.161643  0.242989  0.275385  0.113382  1.0  \n",
       "61580  0.756833  0.558989  0.316419 -0.149685 -0.804837 -1.494884  1.0  \n",
       "61581  0.280322  0.414618  0.609469  0.775086  0.790413  0.534005  1.0  \n",
       "\n",
       "[61582 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('autogluon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d686226f9ed253a4f39741fb3334b92b15a84120bb7d4e6f94583bf764a7e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
